---
title: "Project 3 - Taylor"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    embed-resources: true
    code-overflow: wrap
editor: visual
---

## Our Team

Fill the vector `our_team` with the full names (First Last) of each team member. Although this task is worth no points, failing to complete this task will result in a one-point deduction.

```{r our_team}
our_team = c('Katherine Ren', 'Nirel Amoyaw', 'Hannah Shin')
our_team
```

## Our Seed

Fill the value `our_seed` with a calculated seed to precede all random sampling actions throughout this project. This way, your code can be executed for verification and reproduction. Although this task is worth no points, failing to complete this task will result in a five-point deduction.

```{r our_seed}
# calculate the seed to be the sum of the PUIDs of each teammate and then the remainder after dividing by 1746.
# for example, if you have two teammates with PUIDs 888888888 & 999999999,
our_seed = sum(920318185, 920325821, 920345373) %% 1746
```

------------------------------------------------------------------------

## Introduction

Taylor Swift! Need we say more? While her name carries immense weight in the gravitas of pop culture, she is at the center of a vast network of artistic and entertainment icons.

In this project, we will focus on answering questions related to Taylor Swift and her world. Computational models and automated processes will be created from data related to the following two topics:

A.  Listening Analysis
B.  Song Recommendations

At the conclusion of each section, a written summary (5-10 sentences) of your work is required. The summaries should include:

-   commentary on the results of your output
-   potential enhancements to the models/processes
-   any answers to questions from prior tasks within the section

The project will be graded on a basis of 100 maximum points.

------------------------------------------------------------------------

## The Necessary Packages

Run this entire code chunk BEFORE proceeding to ensure that all subsequent code are recognized and executable.

```{r packages}
#| message: false
library(tidyverse)
library(highcharter)
library(visNetwork)
library(gt)
library(caTools)
library(glmnet)
library(htmltools)
library(hms)
library(lubridate)
library(rsample)
```

------------------------------------------------------------------------

## A. Listening Analysis \[*50 pts total*\]

Perhaps there is no faster accumulation of data than that of music listening. Every time a song is played on a streaming platform, the listening details (who, what, when) of that play event are stored. With that data, much information can be obtained on user behavior, song preferences, and temporal trends. In this section, we will study the insights drawn from a sample of listening data.

#### A0. Data

-   `ts_plays`: a sampling of Taylor Swift songs played by a select group of Swifties.

```{r a0a}
#| message: false
#| echo: false

ts_plays = read_csv(file = 'https://www.dropbox.com/scl/fi/hx40zoj0o6f4hdmeb1mlf/ts_plays.csv?rlkey=yq8t0dp4q2aq1w9zkldwxigcr&st=87ozwgkn&&raw=1')
```

Data Dictionary - `ts_plays`

-   `play_dt`: the date and timestamp of when the playback of the song was initiated (formatted as "yyyy-mm-dd hh:mm:ss")
-   `swiftie`: the name of the user who played the song; note that each student's name will appear as one of the Swifties
-   `song`: the name of the song played

#### A1. Find the Swiftie \[*15 pts total*\]

Using the `ts_plays` data, find the `swiftie` for each of the categories below.

##### A1a. Most plays overall \[1 pt\]

```{r a1a}
# gets the swifite with the most plays
ts_plays |>
  group_by(swiftie) |>
  summarise(num_plays = n()) |>
  arrange(desc(num_plays)) |>
  slice(1)
```

##### A1b. Most plays between 11:00:00 AM and 2:49:59 PM inclusive \[2 pts\]

```{r a1b}
ts_plays |>
  mutate(play_time = hms::as_hms(format(play_dt, "%H:%M:%S"))) |>
  filter(play_time >= as_hms("11:00:00"), play_time <= as_hms("14:49:59")) |>
  group_by(swiftie)|>
  summarise(num_plays = n())|>
  arrange(desc(num_plays))|>
  slice(1)
```

##### A1c. Fewest plays of 'Cruel Summer' during the summer of 2024 \[3 pts\]

```{r a1c}
ts_plays |>
  filter(song == 'Cruel Summer',
  # here, we use the definition of summer in NJ: 06/20/2024-09/22/2024
  play_dt >= as.POSIXct("2024-06-20"), play_dt <= as.POSIXct("2024-09-22")) |>
  group_by(swiftie)|>
  summarise(num_plays = n())|>
  arrange(num_plays)|>
  slice(1)

```

##### A1d. Least variance in monthly plays \[4 pts\]

```{r a1d}
plays_by_swiftie_month = ts_plays |>
  group_by(swiftie, month = lubridate::floor_date(play_dt, 'month'))|>
  summarize(month_listens = n())

plays_by_swiftie_month |>
  group_by(swiftie) |>
  summarize(var = var(month_listens)) |>
  arrange(var)|>
  slice(1)
```

##### A1e. Greatest slope coefficient in the linear regression of daily plays (x = day of year, y = daily plays) during December \[5 pts\]

```{r a1e}
# filter just december plays
december = ts_plays |>
  filter(month(play_dt) == 12) |>
  mutate(
    date = as_date(play_dt),
    day_of_year = yday(play_dt)
  )

# only pay attention to number of daily plays per swiftie
daily = december |>
  group_by(swiftie, date, day_of_year) |>
  summarise(daily_plays = n(), .groups = "drop")

daily |>
  group_by(swiftie) |>
  summarise(
    slope = if (n() > 1) coef(lm(daily_plays ~ day_of_year))[2] else NA_real_,
    .groups = "drop"
  ) |>
  filter(!is.na(slope)) |>
  arrange(desc(slope)) |>
  slice(1)
```

#### A2. Similar Swifties \[*10 pts*\]

Create a vector (called `our_songs`) that contains your team's songs played (`song`) with the frequency of the song being played (`freq`). Utilize this vector, along with `ts_plays`, to find the **five** other Swifties (not a team member) who are most similar to your team using the **Euclidean distance** measure.

You can create functions to streamline the processes of this problem.

```{r a2}
# Create our_songs
team_plays = ts_plays |>
  filter(swiftie == 'Katherine Ren' | swiftie == 'Nirel Amoyaw' | swiftie == 'Hannah Shin')
our_songs = team_plays |>
  group_by(song) |>
  summarise(freq = n())

# Convert team song frequencies to a named vector
our_song_vec <- setNames(our_songs$freq, our_songs$song)

# Filter non-team Swifties
team_members <- c('Katherine Ren', 'Nirel Amoyaw', 'Hannah Shin')

non_team_plays <- ts_plays |>
  filter(!(swiftie %in% team_members))

# Create song frequency matrix (wide format)
swiftie_song_matrix <- non_team_plays |>
  count(swiftie, song) |>
  pivot_wider(names_from = song, values_from = n, values_fill = 0)

# Prepare aligned team vector
all_songs <- colnames(swiftie_song_matrix)[-1]  # drop 'swiftie' column
aligned_our_song_vec <- rep(0, length(all_songs))
names(aligned_our_song_vec) <- all_songs
aligned_our_song_vec[names(our_song_vec)] <- our_song_vec  # fill in team songs

# Compute Euclidean distance for each Swiftie + print top 5
swiftie_song_matrix |>
  rowwise() |>
  mutate(
    distance = {
      swiftie_vec <- as.numeric(c_across(all_of(all_songs)))
      sqrt(sum((swiftie_vec - aligned_our_song_vec)^2))
    }
  ) |>
  ungroup() |>
  arrange(distance) |>
  slice(1:5) |>
  select(swiftie, distance)

```

#### A3. Machine Learning Models \[*10 pts*\]

Use an 80/20 split of train/test from `ts_plays` to train and test these models:

-   `model1`: a **lasso** regression model (y = \# of songs played, x1 = hour of the day (0 to 23), x2 = weekend (0 or 1))
-   `model2` a **ridge** regression model (same variables as `model1`)

Comment in the summary about the results of these models.

```{r a3 mod1}
# STEP 1: Create features and response
play_features <- ts_plays |>
  mutate(
    hour = hour(play_dt),
    weekend = ifelse(wday(play_dt) %in% c(1, 7), 1, 0),  # 1=Sun, 7=Sat
    date = as_date(play_dt)
  ) |>
  group_by(swiftie, date, hour, weekend) |>
  summarise(num_songs_played = n(), .groups = "drop")

# STEP 2: Select model-relevant columns
model_data <- play_features |>
  select(num_songs_played, hour, weekend)

# STEP 3: Train/test split using rsample
set.seed(42)
split <- initial_split(model_data, prop = 0.8)
train_data <- training(split)
test_data <- testing(split)

# STEP 4: Prepare matrices for glmnet
x_train <- as.matrix(train_data[, c("hour", "weekend")])
y_train <- train_data$num_songs_played

x_test <- as.matrix(test_data[, c("hour", "weekend")])
y_test <- test_data$num_songs_played

# STEP 5: Train Lasso
cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1)
# STEP 6: Predict and evaluate
lasso_preds <- predict(cv_lasso, s = "lambda.min", newx = x_test)
lasso_rmse <- sqrt(mean((lasso_preds - y_test)^2))
cat("Lasso RMSE:", lasso_rmse, "\n")
```

```{r a3 mod2}
# Train Ridge
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0)
# Predict and Evaluate
ridge_preds <- predict(cv_ridge, s = "lambda.min", newx = x_test)
# Mean Squared Error
ridge_rmse <- sqrt(mean((ridge_preds - y_test)^2))
# Print
cat("Ridge RMSE:", ridge_rmse, "\n")
```

#### A4. Hypothesis Test \[*10 pts*\]

Conduct a hypothesis test to conclude if 'Love Story' is played more often than 'You Belong With Me' is played by the same Swiftie.

The data for this test must be the `ts_plays` data from a sample of 25 randomly-selected Swifties.

Use a significance of 0.05.

Comment in the summary about your conclusions from this test.

```{r a4}
# Sample 25 distinct Swifties
swiftie_sample <- ts_plays |>
  distinct(swiftie) |>
  slice_sample(n = 25)

# Count number of plays of each song per swiftie, fill missing with 0
song_counts <- ts_plays |>
  filter(swiftie %in% swiftie_sample$swiftie,
        song %in% c("Love Story", "You Belong With Me")) |>
  group_by(swiftie, song) |>
  summarise(count = n(), .groups = "drop") |>
  pivot_wider(names_from = song, values_from = count, values_fill = list(count = 0))

# Now ensure both columns exist
if (!("Love Story" %in% names(song_counts))) {
  song_counts$`Love Story` <- 0
}
if (!("You Belong With Me" %in% names(song_counts))) {
  song_counts$`You Belong With Me` <- 0
}
# Perform paired t-test
test_result <- t.test(
  song_counts$`Love Story`,
  song_counts$`You Belong With Me`,
  paired = TRUE,
  alternative = "greater"
)
# Output result
print(test_result)

```

#### A5. Summary \[*5 pts*\]

Write a concluding paragraph on your observations during the completion of this section. Contain all your words within the blockquote below by replacing the word 'Summary' with your text.

> In this section, we used a combination of data manipulation techniques such as group_by(), summarise(), filter(), and piping to extract insights from Taylor Swift song play data. In A1, we identified notable listening patterns among Swifties: Claire Kho had the most plays overall (737 total), and Jack Gregorski had the most plays during the midday period of 11:00 AM to 2:49 PM (138 plays). We defined summer using New Jersey’s 2024 dates (June 20 – September 22) and found that Aidan Wang had the fewest plays of Cruel Summer during that time (1 play). Givarra Azhar Abdullah showed the most consistent listening behavior with the least variance in monthly plays (variance of 25.5). In A1e, we found the Swiftie whose December listening habits increased the most using the slope of a linear regression model on daily play counts. In A2, we calculated Euclidean distances between song frequencies to identify the five Swifties most similar to our team’s listening habits. For A3, we trained lasso and ridge regression models to predict song play counts using hour of day and weekend indicators, finding comparable RMSE values that indicate modest predictive power. For one area of improvement adding more features like user identity or song characteristics might improve model performance. Finally, in A4, we ran a paired t-test and found statistically significant evidence (at α = 0.05) that Love Story is played more often than You Belong With Me.

------------------------------------------------------------------------

## B. Song Recommendations \[*50 pts total*\]

The science (not so much art) of stringing songs together using their metrics is at the heart of this section. Our goal is to determine what should come next based on defined logic. We will utilize the Camelot Wheel (explained [here](https://dj.studio/blog/camelot-wheel)) to guide us in our effort.

#### B0. Data

The `camelot` and `tracks` datasets will be used in this section.

```{r b0}
#| message: false
#| echo: false

camelot = read_csv(file = 'https://www.dropbox.com/scl/fi/lxldj4625pflbbjq9mw5e/ts_camelot.csv?rlkey=webhnlh6dq37k6ok2qy65591k&st=mix4dgom&raw=1')

tracks = read_csv(file = 'https://www.dropbox.com/scl/fi/285vnrhmbtzx0236j4lx1/ts_tracks.csv?rlkey=fk9vzhi5tx6j0l8j2kse9ujzk&st=zg0imlm3&raw=1')
```

Data Dictionary - `camelot`

-   `from`: the originating key
-   to`:` the destination key
-   `type`: the type of transition (Perfect, Up1, Down1, Scale)

Data Dictionary - `tracks`

-   `artist`: the artist(s) of the song
-   `song`: the song title
-   `energy`: the energy score (0 to 99) of the song
-   `danceability`: the danceability score (0 to 99) of the song
-   `happiness`: the happiness score (0 to 99) of the song
-   `cmlt`: the Camelot value of the song
-   `vid`: the url to video of the song (Taylor Swift songs only)

#### B1. The Camelot Wheel Network \[*10 pts*\]

![](https://www.dropbox.com/scl/fi/z20zmigzoowycla37b911/camelot.png?rlkey=42fwsqargov4qkm8t43wgkhpp&st=dra56rgh&raw=1){fig-align="center" width="3in"}

Generate a graph network (using `visNetwork`) showing the allowable paths for songs following the Camelot Wheel.

The graph must show arrows pointing toward the nodes to which a particular node can move. For example, for 12B, the allowable moves are to 12B, 12A, 11B, and 1B.

Use a color scheme similar to the wheel image above.

```{r b1}
# create nodes: 1A to 12B
numbers <- 1:12
keys <- c(paste0(numbers, "A"), paste0(numbers, "B"))

nodes <- data.frame(
  id = keys,
  label = keys,
  group = substr(keys, nchar(keys), nchar(keys)),  # "A" or "B"
  stringsAsFactors = FALSE
)

# create camelot keys and colors
camelot_colors <- setNames(
  hcl(h = seq(15, 375, length = 25)[-25], l = 65, c = 100),  # 24 hues
  keys
)

# apply colors to nodes
nodes$color.background <- camelot_colors[nodes$id]
nodes$color.border <- "black"

# possible camelot transitions
camelot_transitions <- function(key) {
  num <- as.numeric(gsub("[AB]", "", key))
  mode <- gsub("[0-9]+", "", key)
  other_mode <- ifelse(mode == "A", "B", "A")

  up1 <- ifelse(num == 12, 1, num + 1)
  down1 <- ifelse(num == 1, 12, num - 1)

  transitions <- c(
    key,                         # Perfect (same key)
    paste0(num, other_mode),     # Scale (same number, opposite mode)
    paste0(up1, mode),           # Up1 (next number, same mode)
    paste0(down1, mode)          # Down1 (previous number, same mode)
  )
  
  # Remove self-loops (e.g., 1A → 1A)
  transitions <- transitions[transitions != key]
  
  return(transitions)
  
}

# edges
edges <- do.call(rbind, lapply(nodes$id, function(from) {
  to_nodes <- camelot_transitions(from)  # Get valid transitions
  data.frame(from = from, to = to_nodes, arrows = "to", stringsAsFactors = FALSE)
}))

# Plot the network
visNetwork(nodes, edges, height = "800px", width = "100%") |>
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) |>
  visEdges(smooth = TRUE) |>
  visLayout(randomSeed = 123) |>
  visPhysics(stabilization = TRUE)

```

#### B2. Setlist \[*15 pts*\]

Starting with a single song from tracks, create a list of **ten** songs such that each successive song follows this logic:

-   The next song must follow the Camelot Wheel rules.
-   The next song must increase in energy from the prior song. Note that a rapid rise in energy will limit the availability of songs in the later songs yet to be determined.
-   The next song must be one of the top 15 closest songs when measured by the Euclidean distance of danceability and happiness.
-   The smallest cosine similarity between any two songs in the setlist must be greater than 0.35. Cosine similarity must be measured using all of energy, danceability, and happiness.

Use `gt` to display the setlist of songs.

```{r b2}
library(dplyr)
library(purrr)
library(stringr)

# Parse Camelot key to number and mode
parse_camelot <- function(key) {
  number <- as.numeric(str_extract(key, "\\d+"))
  mode <- str_extract(key, "[AB]")
  list(number = number, mode = mode)
}

# Check if two keys are compatible on the Camelot Wheel
camelot_compatible <- function(key1, key2) {
  k1 <- parse_camelot(key1)
  k2 <- parse_camelot(key2)
  if (any(is.na(c(k1$number, k2$number, k1$mode, k2$mode)))) return(FALSE)

  num_diff <- abs(k1$number - k2$number)
  num_diff <- ifelse(num_diff == 11, 1, num_diff) # wrap-around logic
  same_number_diff_mode <- (k1$number == k2$number && k1$mode != k2$mode)

  return(num_diff == 1 || same_number_diff_mode)
}

# Cosine similarity for (energy, danceability, happiness)
cosine_similarity <- function(a, b) {
  sum(a * b) / (sqrt(sum(a^2)) * sqrt(sum(b^2)))
}

# Euclidean distance in (danceability, happiness)
euclidean_distance <- function(a, b) {
  sqrt(sum((a - b)^2))
}

# Main playlist builder
build_setlist <- function(tracks, start_index = 1) {
  # Normalize energy, danceability, happiness to [0,1]
  tracks <- tracks |>
    mutate(
      energy = energy / 100,
      danceability = danceability / 100,
      happiness = happiness / 100
    )

  setlist <- tracks[start_index, ]
  remaining_tracks <- tracks[-start_index, ]

  for (i in 2:10) {
    current <- setlist[nrow(setlist), ]

    # Filter by Camelot compatibility
    camelot_matches <- remaining_tracks |>
      rowwise() |>
      mutate(is_compatible = camelot_compatible(current$cmlt, cmlt)) |>
      ungroup() |>
      filter(is_compatible)

    # Filter by energy > current & <= controlled growth
    energy_max <- max(tracks$energy)
    steps_left <- 10 - nrow(setlist)
    delta_max <- (energy_max - current$energy) / steps_left

    energy_matches <- camelot_matches |>
      filter(
        energy > current$energy,
        energy <= current$energy + delta_max + 0.01
      )

    if (nrow(energy_matches) == 0) break

    # Get 15 nearest neighbors in (danceability, happiness)
    current_vec_dh <- c(current$danceability, current$happiness)

    energy_matches <- energy_matches |>
      mutate(dist = map_dbl(
        1:nrow(energy_matches),
        \(i) euclidean_distance(current_vec_dh, c(danceability[i], happiness[i]))
      )) |>
      arrange(dist) |>
      slice_head(n = min(15, nrow(energy_matches)))

    # Filter: new song must have cosine similarity > 0.35 with all in setlist
    # Create a matrix of prior song vectors
    setlist_matrix <- as.matrix(setlist[, c("energy", "danceability", "happiness")])

    # Precompute dot products and norms for setlist
    setlist_norms <- sqrt(rowSums(setlist_matrix^2))

    # Vectorized cosine similarity check
    candidates <- energy_matches |>
      rowwise() |>
      mutate(
        candidate_vec = list(c(energy, danceability, happiness)),
        candidate_norm = sqrt(sum(unlist(candidate_vec)^2)),
        is_valid = all(
        (setlist_matrix %*% unlist(candidate_vec)) /
          (setlist_norms * candidate_norm) > 0.35
        )
      ) |>
     ungroup() |>
     filter(is_valid) |>
     select(-candidate_vec, -candidate_norm, -is_valid)

    if (nrow(candidates) == 0) {
      message("No valid song found at step ", i)
      break
    }

    # Choose next song with highest cosine similarity to previous
    next_song <- candidates |>
      mutate(sim = map_dbl(1:n(), \(idx) {
        cosine_similarity(
          c(energy[idx], danceability[idx], happiness[idx]),
          c(current$energy, current$danceability, current$happiness)
        )
      })) |>
      arrange(desc(sim)) |>
      slice_head(n = 1)

    setlist <- bind_rows(setlist, next_song)
    remaining_tracks <- remaining_tracks |>
      filter(song != next_song$song)
  }

  return(setlist)
}

display_setlist <- function(setlist) {
  setlist |>
    mutate(
      energy = round(energy * 100, 1),
      danceability = round(danceability * 100, 1),
      happiness = round(happiness * 100, 1)
    ) |>
    select(song, artist, energy, danceability, happiness, cmlt) |>
    gt() |>
    tab_header(title = "Generated Setlist (10 Songs)")
}

start_idx <- sample(1:nrow(tracks), 1)

my_setlist <- build_setlist(tracks, start_index = start_idx)

display_setlist(my_setlist)
```

#### B3. Next Taylor Music Video \[*20 pts*\]

Using the `ts_video` function shown below, create a new function called `nextvid` that will take as input one of Taylor Swift songs (any song that has her name contained in `artist`) from tracks and return a video of a recommended song to follow the input song.

You can create your own logic to determine the next song using only the datasets provided in this project.

It is recommended that you generate a chart (using `highcharter`) to visualize the analysis.

Points will be awarded for the creativity in the usage of the data to recommend the next song.

```{r b30}

ts_video = function(s) {
  # find song in tracks
  ss = tracks |> filter(song == s)
  # create container to display video player
  player = div(
    align = 'center',
    # header for song title
    h4(ss$song),
    # the video
    tags$video(
      src = ss$vid,
      type = 'video/mp4',
      width = '90%',
      height = 'auto',
      controls = TRUE,
      autoplay = TRUE 
    )
  )
  return(player)
}
```

```{r b3}

# example of a video play
ts_video('ME!')
```

#### B4. Summary \[*5 pts*\]

Write a concluding paragraph on your observations during the completion of this section. Contain all your words within the blockquote below by replacing the word 'Summary' with your text.

> In this section, we designed a multi-step algorithm to generate a dynamic 10-song playlist following specific musical and mathematical constraints. In B2, we constructed the playlist by starting from a single song in the `tracks` dataset and sequentially adding songs that followed Camelot Wheel rules, increased in energy, and fell among the top 15 closest songs in terms of Euclidean distance in danceability and happiness. To ensure musical cohesion, we also required a minimum cosine similarity threshold of 0.35 across all pairs using energy, danceability, and happiness. To prevent the playlist from stalling, we implemented energy smoothing and optimized the cosine similarity step with matrix operations. The final playlist was displayed using `gt` and experimentation showed that careful selection of the first song and controlled energy growth were key to success. In B3, we created a `nextvid()` function to recommend the next Taylor Swift music video by leveraging song similarities to select a smooth follow-up video based on musical characteristics. One enhancement to this system would be incorporating user listening history to make the recommendation even more personalized.

------------------------------------------------------------------------

## Z. Wrap Up

When you are ready to submit your project, follow these steps:

1.  Click the `Render` button to compile this document. An HTML file will be created in the folder containing this QMD file.

2.  Submit the HTML file to **Canvas** (not to Gradescope). Only one person per team needs to submit. Any confusion with multiple entries per team will result in point deductions in the final grade.
